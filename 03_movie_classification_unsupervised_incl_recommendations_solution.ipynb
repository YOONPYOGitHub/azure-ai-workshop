{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì„ë² ë”©ì„ ì‚¬ìš©í•œ ë¹„ì§€ë„ í´ëŸ¬ìŠ¤í„°ë§ ë° ëª…ëª…ëœ í´ëŸ¬ìŠ¤í„° (ê·¸ë¦¬ê³  ê¸°íƒ€ ì¬ë¯¸ìˆëŠ” ì‘ì—…)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” [Top 10000 Popular Movies Dataset](https://www.kaggle.com/datasets/db55ac3dfd0098a0cf96dd542807f9253a16587ff233e06baef372bccfd09942)ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‚¬ìš©í•˜ì—¬ ì˜í™” ì„¤ëª…ì— ëŒ€í•œ ì„ë² ë”©ì„ ê³„ì‚°í•œ í›„ k-meansë¥¼ ì ìš©í•˜ì—¬ ìœ ì‚¬í•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ë¥¼ ì–»ì€ í›„ì—ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í´ëŸ¬ìŠ¤í„°ì˜ ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë°©ë²•ì˜ ì¢…ë¥˜\n",
    "\n",
    "ë¨¸ì‹ ëŸ¬ë‹ì€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ í¬ê²Œ 4ê°€ì§€ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 1ï¸âƒ£ ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)\n",
    "**ë ˆì´ë¸”(ì •ë‹µ) ì—†ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•˜ëŠ” í•™ìŠµ**\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- âœ… ë ˆì´ë¸”ì´ í•„ìš” ì—†ìŒ (ë¹„ìš© ì ˆê°)\n",
    "- âœ… ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬\n",
    "- âŒ ê²°ê³¼ í•´ì„ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ\n",
    "\n",
    "**ì£¼ìš” ê¸°ë²•:**\n",
    "- **í´ëŸ¬ìŠ¤í„°ë§**: K-means, DBSCAN, ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§\n",
    "- **ì°¨ì› ì¶•ì†Œ**: PCA, t-SNE, UMAP\n",
    "- **ì´ìƒ íƒì§€**: Isolation Forest, One-Class SVM\n",
    "\n",
    "**í™œìš© ì‚¬ë¡€:**\n",
    "```\n",
    "- ê³ ê° ì„¸ë¶„í™” (Customer Segmentation)\n",
    "- ì¶”ì²œ ì‹œìŠ¤í…œ (Recommendation System)\n",
    "- ì´ìƒ ê±°ë˜ íƒì§€ (Anomaly Detection)\n",
    "- ë°ì´í„° ì‹œê°í™” ë° íƒìƒ‰\n",
    "```\n",
    "\n",
    "**ì´ ë…¸íŠ¸ë¶ì˜ ì˜ˆì‹œ:**\n",
    "- ì˜í™”ë¥¼ 5ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ìë™ ë¶„ë¥˜ (K-means)\n",
    "- ê³ ì°¨ì› ì„ë² ë”©ì„ 2Dë¡œ ì‹œê°í™” (t-SNE)\n",
    "\n",
    "---\n",
    "\n",
    "### 2ï¸âƒ£ ì§€ë„ í•™ìŠµ (Supervised Learning)\n",
    "**ë ˆì´ë¸”(ì •ë‹µ)ì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” í•™ìŠµ**\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- âœ… ëª…í™•í•œ ëª©í‘œì™€ í‰ê°€ ê¸°ì¤€\n",
    "- âœ… ë†’ì€ ì •í™•ë„\n",
    "- âŒ ë ˆì´ë¸” ì‘ì—… ë¹„ìš©ì´ í¼\n",
    "\n",
    "**ì£¼ìš” ê¸°ë²•:**\n",
    "- **ë¶„ë¥˜ (Classification)**: ë¡œì§€ìŠ¤í‹± íšŒê·€, ê²°ì • íŠ¸ë¦¬, Random Forest, SVM, ì‹ ê²½ë§\n",
    "- **íšŒê·€ (Regression)**: ì„ í˜• íšŒê·€, Ridge, Lasso, XGBoost\n",
    "\n",
    "**í™œìš© ì‚¬ë¡€:**\n",
    "```\n",
    "- ìŠ¤íŒ¸ ë©”ì¼ í•„í„°ë§ (ë¶„ë¥˜)\n",
    "- ì§ˆë³‘ ì§„ë‹¨ (ë¶„ë¥˜)\n",
    "- ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ (íšŒê·€)\n",
    "- ë§¤ì¶œ ì˜ˆì¸¡ (íšŒê·€)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3ï¸âƒ£ ìê¸° ì§€ë„ í•™ìŠµ (Self-Supervised Learning)\n",
    "**ë°ì´í„° ìì²´ì—ì„œ ë ˆì´ë¸”ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ í•™ìŠµí•˜ëŠ” ë°©ë²•**\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- âœ… ëŒ€ê·œëª¨ ë¹„ë ˆì´ë¸” ë°ì´í„° í™œìš©\n",
    "- âœ… ì‚¬ì „í•™ìŠµ(Pre-training)ì— íš¨ê³¼ì \n",
    "- âœ… ë ˆì´ë¸” ë¹„ìš© ì ˆê°\n",
    "\n",
    "**ì£¼ìš” ê¸°ë²•:**\n",
    "- **Masked Language Modeling**: ë¬¸ì¥ì—ì„œ ë‹¨ì–´ë¥¼ ê°€ë¦¬ê³  ì˜ˆì¸¡ (BERT, GPT)\n",
    "- **Contrastive Learning**: ìœ ì‚¬í•œ ë°ì´í„°ëŠ” ê°€ê¹ê²Œ, ë‹¤ë¥¸ ë°ì´í„°ëŠ” ë©€ê²Œ (SimCLR, MoCo)\n",
    "- **Autoencoder**: ì…ë ¥ì„ ì••ì¶•í–ˆë‹¤ê°€ ë³µì›\n",
    "\n",
    "**í™œìš© ì‚¬ë¡€:**\n",
    "```\n",
    "- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì‚¬ì „í•™ìŠµ (GPT, BERT)\n",
    "- ì´ë¯¸ì§€ í‘œí˜„ í•™ìŠµ (ResNet, Vision Transformer)\n",
    "- ìŒì„± ì¸ì‹ ëª¨ë¸ ì‚¬ì „í•™ìŠµ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4ï¸âƒ£ ê°•í™” í•™ìŠµ (Reinforcement Learning)\n",
    "**í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©° ë³´ìƒì„ ìµœëŒ€í™”í•˜ëŠ” í–‰ë™ì„ í•™ìŠµ**\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- âœ… ìˆœì°¨ì  ì˜ì‚¬ê²°ì • ë¬¸ì œì— ê°•í•¨\n",
    "- âœ… ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•œ í•™ìŠµ\n",
    "- âŒ í•™ìŠµì´ ë¶ˆì•ˆì •í•˜ê³  ëŠë¦¼\n",
    "\n",
    "**ì£¼ìš” ê°œë…:**\n",
    "- **ì—ì´ì „íŠ¸(Agent)**: í•™ìŠµí•˜ëŠ” ì£¼ì²´\n",
    "- **í™˜ê²½(Environment)**: ì—ì´ì „íŠ¸ê°€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì„¸ê³„\n",
    "- **í–‰ë™(Action)**: ì—ì´ì „íŠ¸ì˜ ì„ íƒ\n",
    "- **ë³´ìƒ(Reward)**: í–‰ë™ì— ëŒ€í•œ í”¼ë“œë°±\n",
    "\n",
    "**ì£¼ìš” ê¸°ë²•:**\n",
    "- Q-Learning, DQN (Deep Q-Network)\n",
    "- Policy Gradient, PPO (Proximal Policy Optimization)\n",
    "- Actor-Critic, A3C\n",
    "\n",
    "**í™œìš© ì‚¬ë¡€:**\n",
    "```\n",
    "- ê²Œì„ AI (AlphaGo, Dota 2)\n",
    "- ììœ¨ì£¼í–‰ ìë™ì°¨\n",
    "- ë¡œë´‡ ì œì–´\n",
    "- ì¶”ì²œ ì‹œìŠ¤í…œ ìµœì í™”\n",
    "- ëŒ€í™”í˜• AI (ChatGPTì˜ RLHF)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š í•™ìŠµ ë°©ë²• ë¹„êµí‘œ\n",
    "\n",
    "| í•™ìŠµ ë°©ë²• | ë ˆì´ë¸” í•„ìš” | ì£¼ìš” ìš©ë„ | ì¥ì  | ë‹¨ì  |\n",
    "|----------|----------|---------|------|------|\n",
    "| **ë¹„ì§€ë„ í•™ìŠµ** | âŒ ì—†ìŒ | íŒ¨í„´ ë°œê²¬, í´ëŸ¬ìŠ¤í„°ë§ | ë ˆì´ë¸” ë¹„ìš© ì—†ìŒ | í•´ì„ ì–´ë ¤ì›€ |\n",
    "| **ì§€ë„ í•™ìŠµ** | âœ… í•„ìš” | ë¶„ë¥˜, ì˜ˆì¸¡ | ë†’ì€ ì •í™•ë„ | ë ˆì´ë¸” ë¹„ìš© í¼ |\n",
    "| **ìê¸° ì§€ë„ í•™ìŠµ** | ğŸ”„ ìë™ ìƒì„± | ëŒ€ê·œëª¨ ì‚¬ì „í•™ìŠµ | í™•ì¥ì„± ì¢‹ìŒ | íŠ¹ì • ë„ë©”ì¸ ì „ë¬¸ì„± ë¶€ì¡± |\n",
    "| **ê°•í™” í•™ìŠµ** | â­ ë³´ìƒ ì‹ í˜¸ | ì˜ì‚¬ê²°ì •, ì œì–´ | ë³µì¡í•œ ì „ëµ í•™ìŠµ | í•™ìŠµ ë¶ˆì•ˆì •, ëŠë¦¼ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ì´ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ì„ë² ë”© ìƒì„±**: ì˜í™” ì„¤ëª… â†’ ë²¡í„° ë³€í™˜\n",
    "2. **K-means í´ëŸ¬ìŠ¤í„°ë§**: ìœ ì‚¬í•œ ì˜í™” ìë™ ê·¸ë£¹í™” (ë ˆì´ë¸” ì—†ìŒ)\n",
    "3. **t-SNE ì‹œê°í™”**: ê³ ì°¨ì› ë°ì´í„° â†’ 2D ì‹œê°í™”\n",
    "4. **ì¶”ì²œ ì‹œìŠ¤í…œ**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ìœ ì‚¬ ì˜í™” ì¶”ì²œ\n",
    "\n",
    "ë ˆì´ë¸”ì´ ì—†ëŠ” ìƒíƒœì—ì„œ ì˜í™”ì˜ íŒ¨í„´ì„ ë°œê²¬í•˜ê³  ìë™ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn: ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# K-means í´ëŸ¬ìŠ¤í„°ë§, t-SNE ì‹œê°í™”ì— ì‚¬ìš©\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-12-01-preview\"\n",
    ")\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL_NAME\")\n",
    "model = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`movies.csv`ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movies.csv')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, ìƒˆë¡œìš´ ì—´ì„ ìƒì„±í•˜ê³  ê° ì„ë² ë”©ì— í•„ìš”í•œ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•´ ë´…ì‹œë‹¤. ì´ë¥¼ í†µí•´ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ë° ë“œëŠ” ë¹„ìš©ì„ ì¶”ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the dataframe where you put the token count of the review\n",
    "df = df.assign(token_count=df['overview'].apply(lambda x: len(encoding.encode(x))))\n",
    "\n",
    "# print the first 5 rows of the dataframe, then also the total number of tokens\n",
    "total_tokens = df['token_count'].sum()\n",
    "\n",
    "cost_for_embeddings = total_tokens / 1000 * 0.0001\n",
    "print(f\"Test would cost ${cost_for_embeddings} for embeddings\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„ë² ë”© ë©”ì„œë“œë¥¼ ì •ì˜í•´ ë´…ì‹œë‹¤. Azure OpenAI ì„œë¹„ìŠ¤ì˜ TPS ì œí•œì— ë„ë‹¬í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ìë™ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µí•˜ëŠ” tenacityì˜ ì‚¬ìš©ì— ì£¼ëª©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "def get_embedding(text) -> list[float]:\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=EMBEDDING_MODEL).data[0].embedding\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„ë² ë”©ì„ ìƒì„±í•´ ë´…ì‹œë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(embedding=df['overview'].apply(lambda x: get_embedding(x)))\n",
    "df.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ, KMeansë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì— í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê²½ìš°, 5ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ì„ íƒí•˜ì§€ë§Œ, ì´ê²ƒì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train k-means on df embeddings\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\n",
    "kmeans.fit(df['embedding'].to_list())\n",
    "df = df.assign(cluster=kmeans.labels_)\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ê° í–‰ì— í´ëŸ¬ìŠ¤í„°ê°€ ìˆìœ¼ë¯€ë¡œ t-SNEë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ 2ì°¨ì› ê³µê°„ìœ¼ë¡œ íˆ¬ì˜í•˜ê³  í´ëŸ¬ìŠ¤í„°ë¥¼ ì‹œê°í™”í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2, perplexity=50, random_state=42, init=\"random\", learning_rate=200\n",
    ")\n",
    "\n",
    "matrix = np.vstack(df.embedding.values)\n",
    "print(matrix.shape)\n",
    "vis_dims2 = tsne.fit_transform(matrix)\n",
    "\n",
    "x = [x for x, y in vis_dims2]\n",
    "y = [y for x, y in vis_dims2]\n",
    "\n",
    "for category, color in enumerate([\"purple\", \"green\", \"red\", \"blue\",\"yellow\", 'black', 'orange', 'brown', 'pink', 'grey']):\n",
    "    xs = np.array(x)[df.cluster == category]\n",
    "    ys = np.array(y)[df.cluster == category]\n",
    "    plt.scatter(xs, ys, color=color, alpha=0.3)\n",
    "\n",
    "    avg_x = xs.mean()\n",
    "    avg_y = ys.mean()\n",
    "\n",
    "    plt.scatter(avg_x, avg_y, marker=\"x\", color=color, s=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìŒ, ì˜ˆìƒí–ˆë˜ ëŒ€ë¡œ ê·¸ë‹¤ì§€ ì¢‹ì•„ ë³´ì´ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ì˜í™”ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ë‹¨ 5ê°œì˜ í´ëŸ¬ìŠ¤í„°ë§Œìœ¼ë¡œëŠ” ì´ìƒì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìì„¸íˆ ë³´ë©´ í´ëŸ¬ìŠ¤í„°ë¥¼ ë‹®ì€ ëŒ€ëµì ì¸ ëª¨ì–‘ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì˜í™”ëŠ” ë‘ ê°œ ì´ìƒì˜ ì¹´í…Œê³ ë¦¬ì— ì†í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì–´ëŠ ì •ë„ ë§ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ê°€ì ¸ì™€ OpenAIì— ë³´ë‚´ê³  ê³µí†µ ì£¼ì œë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 10 movies from each cluster and write a prompt that asks what these have in common\n",
    "# ideally you would use more movies than 10, but this is just a demo\n",
    "\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    reviews = df[df['cluster'] == i]['overview'].sample(10)\n",
    "    reviews = \"\\n\".join(reviews.values.tolist())\n",
    "    \n",
    "    prompt = f\"ë‹¤ìŒì€ 10ê°œì˜ ì˜í™” ì„¤ëª…ì…ë‹ˆë‹¤: \\n{reviews}ì´ë“¤ì˜ ê³µí†µì ì„ ì„¸ ë‹¨ì–´ë¡œ ì ì–´ ë³´ì„¸ìš”.\"\n",
    "    print(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages = [\n",
    "                        {\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                        {\"role\":\"user\",\"content\":prompt}\n",
    "                    ])\n",
    "    topic_content = response.choices[0].message.content                \n",
    "\n",
    "    print(f\"Cluster {i} topics: {topic_content}\")\n",
    "    movies = df[df['cluster'] == i]['original_title'].sample(25)\n",
    "    print(f\"Movies from cluster {i}: {', '.join(movies.values.tolist())}\")\n",
    "    print(\"================\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë ‡ê²Œ ë‚˜ì˜ì§€ ì•Šì•„ ë³´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ì‹œ ë§í•˜ì§€ë§Œ, ê° í´ë˜ìŠ¤ì— ëŒ€í•´ 10ê°œì˜ ìƒ˜í”Œë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ ì ë‹¤ëŠ” ì ì„ ê³ ë ¤í•  ë•Œ ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ì¨Œë“  ì˜í™” ì œëª©ì„ ë³´ë©´ ì¼ë¶€ ì£¼ì œê°€ ì‹¤ì œë¡œ ê½¤ ê´œì°®ê²Œ ë³´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œëŠ” ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ê°„ë‹¨í•œ ì¶”ì²œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•œ ë²ˆ ì‹œë„í•´ ë´…ì‹œë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a movie that exists in df, keeping in mind we only have 500 movies in it!\n",
    "movie = \"Frozen\"\n",
    "\n",
    "# get embedding for movie\n",
    "e = df[df['original_title'] == movie]['embedding'].values[0]\n",
    "\n",
    "# get cosine similarity between movie and all other movies and sort ascending\n",
    "similarities = df['embedding'].apply(lambda x: cosine_similarity(x, e))\n",
    "\n",
    "# get most similar movies\n",
    "movies = df.assign(similarity=similarities).sort_values(by='similarity', ascending=False)[['original_title', 'similarity', 'overview']]\n",
    "movies[0:6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§ˆì§€ë§‰ ê²ƒì„ ì œì™¸í•˜ê³ ëŠ” ì‹¤ì œë¡œ ê½¤ ê´œì°®ì•„ ë³´ì…ë‹ˆë‹¤... ì•„ë§ˆë„ ì¶”ì²œì— ì˜í™” ì¹´í…Œê³ ë¦¬ì™€ ì—°ë ¹ ë“±ê¸‰ì„ ì¶”ê°€í–ˆë‹¤ë©´ ë” ìœ ìš©í–ˆì„ ê²ƒì…ë‹ˆë‹¤... :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì„ë² ë”©ì„ í™œìš©í•œ ì‹¤ì „ ì‚¬ìš© ì‚¬ë¡€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ì„ë² ë”© ê¸°ìˆ ì„ ë‹¤ì–‘í•œ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì„ë² ë”©ì„ í™œìš©í•œ ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€ì…ë‹ˆë‹¤.\n",
    "\n",
    "### 1 **ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ**\n",
    "**ì´ ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ ê²ƒê³¼ ë™ì¼í•œ ë°©ì‹**\n",
    "\n",
    "**í™œìš© ë¶„ì•¼:**\n",
    "- **ì´ì»¤ë¨¸ìŠ¤**: ìœ ì‚¬í•œ ìƒí’ˆ ì¶”ì²œ (\"ì´ ìƒí’ˆê³¼ ë¹„ìŠ·í•œ ìƒí’ˆ\")\n",
    "- **ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤**: Netflix, YouTube ìŠ¤íƒ€ì¼ ì½˜í…ì¸  ì¶”ì²œ\n",
    "- **ë‰´ìŠ¤ í”Œë«í¼**: ì½ê³  ìˆëŠ” ê¸°ì‚¬ì™€ ìœ ì‚¬í•œ ê¸°ì‚¬ ì¶”ì²œ\n",
    "- **ìŒì•… ì„œë¹„ìŠ¤**: ë¹„ìŠ·í•œ ê³¡, ì•„í‹°ìŠ¤íŠ¸ ì¶”ì²œ\n",
    "\n",
    "---\n",
    "\n",
    "### 2 **ì‹œë§¨í‹± ê²€ìƒ‰ (Semantic Search)**\n",
    "**í‚¤ì›Œë“œê°€ ì•„ë‹Œ \"ì˜ë¯¸\" ê¸°ë°˜ ê²€ìƒ‰**\n",
    "\n",
    "**í™œìš© ë¶„ì•¼:**\n",
    "- **ê¸°ì—… ë¬¸ì„œ ê²€ìƒ‰**: ë‚´ë¶€ ì§€ì‹ë² ì´ìŠ¤, ë§¤ë‰´ì–¼ ê²€ìƒ‰\n",
    "- **ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰**: ìœ ì‚¬ íŒë¡€, ë²•ë¥  ì¡°í•­ ê²€ìƒ‰\n",
    "- **í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰**: ì£¼ì œê°€ ìœ ì‚¬í•œ ë…¼ë¬¸ ì°¾ê¸°\n",
    "- **FAQ ì‹œìŠ¤í…œ**: ì§ˆë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ë‹µë³€ ë§¤ì¹­\n",
    "\n",
    "**ì¥ì :**\n",
    "- ë™ì˜ì–´, ìœ ì‚¬ í‘œí˜„ ìë™ ì¸ì‹\n",
    "- ë‹¤êµ­ì–´ ê²€ìƒ‰ ê°€ëŠ¥\n",
    "- ì˜¤íƒ€ì— ê°•í•¨\n",
    "\n",
    "---\n",
    "\n",
    "### 3 **ë‹¤êµ­ì–´ ê²€ìƒ‰**\n",
    "**ì–¸ì–´ê°€ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ ê²€ìƒ‰ ê°€ëŠ¥**\n",
    "\n",
    "**í™œìš© ë¶„ì•¼:**\n",
    "- **ê¸€ë¡œë²Œ ì´ì»¤ë¨¸ìŠ¤**: í•œêµ­ì–´ ê²€ìƒ‰ â†’ ì˜ì–´ ìƒí’ˆë„ ê²€ìƒ‰\n",
    "- **ë‹¤êµ­ì–´ ê³ ê° ì§€ì›**: ì–´ë–¤ ì–¸ì–´ë¡œ ì§ˆë¬¸í•´ë„ ë‹µë³€ ê°€ëŠ¥\n",
    "- **êµ­ì œ ë‰´ìŠ¤ ì„œë¹„ìŠ¤**: ì–¸ì–´ ê²½ê³„ ì—†ëŠ” ê¸°ì‚¬ ì¶”ì²œ\n",
    "- **ë²ˆì—­ ì—†ëŠ” ì •ë³´ ì ‘ê·¼**: ì™¸êµ­ ë¬¸ì„œ ì§ì ‘ ê²€ìƒ‰\n",
    "\n",
    "---\n",
    "\n",
    "ì„ë² ë”©ì€ í˜„ëŒ€ AI ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
